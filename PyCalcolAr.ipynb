{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCalcolAr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importare le librerie utili per la creazione del codice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "# se ricevi un errore \"ModuleNotFoundError\", devi istallare il pacchetto https://github.com/Phlya/adjustText:\n",
    "# se usi Anaconda, apri \"Anaconda prompt\" dal menu Start e esegui   conda install -c conda-forge adjusttext\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importazione del file sample_name_config.xlsx \n",
    "#### (unico parametro da modificare nel codice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2523916399.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [52]\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# indicate the path of the sample_name_config.xlsx file\n",
    "\n",
    "while True:\n",
    "\n",
    "    config_path = input('Enter the path of the config file for the sample or \"exit\": ')\n",
    "    \n",
    "    if config_path == 'exit':\n",
    "        break\n",
    "    \n",
    "    elif os.path.exists(config_path) is False:\n",
    "        print('The path does not exist')\n",
    "        continue\n",
    "    \n",
    "    else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sheet \"analysis_parameter\" from the sample_name_config.xlsx file\n",
    "\n",
    "df_config_sample_parameters = pd.read_excel(\n",
    "    io=config_path,\n",
    "    sheet_name='analysis_parameter'\n",
    ")\n",
    "\n",
    "#set the input values from the sample_name_config.xlsx file\n",
    "\n",
    "#nome del campione\n",
    "sample_name = df_config_sample_parameters.iat[0, 1]\n",
    "\n",
    "# definire il percorso del file calibrazione\n",
    "file_path_36 = df_config_sample_parameters.iat[1, 1]\n",
    "\n",
    "# definire il percorso dei file dati\n",
    "file_path_4 = df_config_sample_parameters.iat[2, 1]\n",
    "file_path_22 = df_config_sample_parameters.iat[3, 1]\n",
    "file_path_faradaysolo = df_config_sample_parameters.iat[4, 1]\n",
    "\n",
    "# filtrare il dataframe per numero run\n",
    "run_start = df_config_sample_parameters.iat[5, 1]\n",
    "run_end = df_config_sample_parameters.iat[6, 1]\n",
    "\n",
    "# days passed between the irradiation and the measurement of the sample\n",
    "delay = df_config_sample_parameters.iat[7, 1]\n",
    "\n",
    "# sample_weight, (cambia per ogni campione) \n",
    "sample_weight = df_config_sample_parameters.iat[8, 1]\n",
    "\n",
    "# J_factor e J_factor_errors, (cambia per ogni campione) \n",
    "J_factor = df_config_sample_parameters.iat[9, 1]\n",
    "J_factor_errors = df_config_sample_parameters.iat[10, 1]\n",
    "\n",
    "\n",
    "# sensitivity, (valore misurato un paio di volte l'anno) \n",
    "sensitivity = df_config_sample_parameters.iat[11, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valori misurati 4/5 di volte l'anno\n",
    "\n",
    "# update_data = df_config_sample_parameters.iat[12, 1]\n",
    "\n",
    "background_spectrometer_dict = {'Background 40Ar': [df_config_sample_parameters.iat[13, 1], df_config_sample_parameters.iat[13, 2]],\n",
    "                                'Background 39Ar': [df_config_sample_parameters.iat[14, 1], df_config_sample_parameters.iat[14, 2]],\n",
    "                                'Background 38Ar': [df_config_sample_parameters.iat[15, 1], df_config_sample_parameters.iat[15, 2]],\n",
    "                                'Background 37Ar': [df_config_sample_parameters.iat[16, 1], df_config_sample_parameters.iat[16, 2]],\n",
    "                                'Background 36Ar': [df_config_sample_parameters.iat[17, 1], df_config_sample_parameters.iat[17, 2]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabella: IRRADIATIONS CONSTANTS \n",
    "#### (NON SONO DA MODIFICARE, valori costanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sheet \"irradiation_constants\" from the sample_name_config.xlsx file\n",
    "\n",
    "df_config_irradiation_constants = pd.read_excel(\n",
    "    io=config_path,\n",
    "    sheet_name='irradiation_constants'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "irradiations_constants_dict = {'Atmospheric Ratio': [df_config_irradiation_constants.iat[0, 1], df_config_irradiation_constants.iat[0, 2]], \n",
    "                               '(36Ar/37Ar) Ca': [df_config_irradiation_constants.iat[1, 1], df_config_irradiation_constants.iat[1, 2]],\n",
    "                               '(38Ar/37Ar) Ca': [df_config_irradiation_constants.iat[2, 1], df_config_irradiation_constants.iat[2, 2]],\n",
    "                               '(39Ar/37Ar) Ca': [df_config_irradiation_constants.iat[3, 1], df_config_irradiation_constants.iat[3, 2]],\n",
    "                               'Lambda Ar37 [1/d]': [df_config_irradiation_constants.iat[4, 1], df_config_irradiation_constants.iat[4, 2]],\n",
    "                               'Lambda Ar40 [1/Ma]': [df_config_irradiation_constants.iat[5, 1], df_config_irradiation_constants.iat[5, 2]],\n",
    "                               'Interference 40K': [df_config_irradiation_constants.iat[6, 1], df_config_irradiation_constants.iat[6, 2]],\n",
    "                               'Coefficient 39Ar for J': [df_config_irradiation_constants.iat[7, 1], df_config_irradiation_constants.iat[7, 2]],\n",
    "                               'Coefficient Ca/K': [df_config_irradiation_constants.iat[8, 1], df_config_irradiation_constants.iat[8, 2]],\n",
    "                               'Coefficient Cl/K': [df_config_irradiation_constants.iat[9, 1], df_config_irradiation_constants.iat[9, 2]],}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importazione files dello spettrometro\n",
    "### > file Triplo36 (file di calibrazione dell'aria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to change the file name of triplo36_..._.txt, see above\n",
    "\n",
    "# definire la lista con gli indici delle colonne \n",
    "columns_names=['40F', 'err 40F', '38IC0', 'err 38IC0', '36IC1', 'err 36IC1', '36IC0', 'err 36IC0','36F', 'err 36F', 'gain IC0/IC1', 'err gain IC0/IC1', 'gain F/IC1', 'err gain F/IC1' , 'gain F/IC0', 'err gain F/IC0', '40F/36IC1', 'err 40F/36IC1 ', '40F/36F', 'err 40F/36F', '40F/36IC0', 'err 40F/36IC0' , '38IC0/36IC0', 'err 38IC0/36IC0', 'Run', 'Path']\n",
    "\n",
    "# definire le colonne che contengono dati numerici (ad eccezione delle colonne 'Run' e 'Path')\n",
    "columns_numeric=['40F', 'err 40F', '38IC0', 'err 38IC0', '36IC1', 'err 36IC1', '36IC0', 'err 36IC0','36F', 'err 36F', 'gain IC0/IC1', 'err gain IC0/IC1', 'gain F/IC1', 'err gain F/IC1' , 'gain F/IC0', 'err gain F/IC0', '40F/36IC1', 'err 40F/36IC1 ', '40F/36F', 'err 40F/36F', '40F/36IC0', 'err 40F/36IC0' , '38IC0/36IC0', 'err 38IC0/36IC0']\n",
    "\n",
    "# importare il file utilizzando caratteri separatori (sep = '\\t|,') '\\t' = tab, ',' = virgola\n",
    "airpipette_data = pd.read_csv(file_path_36, header = None, names = columns_names, sep = '\\t|,', engine = 'python')\n",
    "\n",
    "# eliminare i caratteri \"{}\" dalle colonne relative all'errore\n",
    "airpipette_data = airpipette_data.replace([\"{\",\"}\"], [\"\",\"\"], regex=True)\n",
    "\n",
    "# convertire tutte le colonne del dataframe a numeric (float64)\n",
    "for i in columns_numeric:\n",
    "    airpipette_data[i] = pd.to_numeric(airpipette_data[i])\n",
    "    \n",
    "# definire un dataframe con le \"colonne utili\" (foglio airpipette_data)\n",
    "airpipette_data = airpipette_data[['40F', 'err 40F', '38IC0', 'err 38IC0', '36IC1', 'err 36IC1', '36IC0', 'err 36IC0', '36F', 'err 36F', '40F/36F', 'err 40F/36F', 'Run', 'Path']]\n",
    "\n",
    "# stampare il dataframe 'airpipette_data'\n",
    "# print(\"Air pipette initial imported data:\")\n",
    "\n",
    "# dividere la colonna 'Run' in due colonne: nome del run e data/ora\n",
    "run_split = airpipette_data['Run'].str.split(\" run on \")\n",
    "\n",
    "# formattare la colonna con il nome del run (del campione) in una serie pandas e associarle un nome \n",
    "run_name = run_split.str[0]\n",
    "run_name = run_name.replace([\"'\"], [\"\"], regex=True)\n",
    "run_name.name = 'Run_Name'\n",
    "\n",
    "# formattare la colonna con il numero del run \n",
    "run_number = airpipette_data['Path'].str.split('.').str[0]\n",
    "run_number = run_number.str.split('_').str[-1]\n",
    "run_number.name= 'Run_Number'\n",
    "run_number = pd.to_numeric(run_number)\n",
    "\n",
    "# formattare la colonna con la data e l'ora in una serie pandas e associarle un nome, convertire il dato in datetime64\n",
    "dataora = run_split.str[1]\n",
    "dataora.name = 'Date_Time'\n",
    "dataora = pd.to_datetime(dataora)\n",
    "\n",
    "# concatenare le nuove colonne all'inizio del dataframe airpipette_data\n",
    "airpipette_data = pd.concat([run_name, run_number, dataora, airpipette_data], axis = 1)\n",
    "\n",
    "# eliminare la colonna 'Run' (non più utilizzata)\n",
    "airpipette_data.drop('Run',axis=1, inplace=True)\n",
    "\n",
    "# conversione valore da count a V per tutti IC0,IC1 e relativi errori... (n / 62415000)\n",
    "airpipette_data.loc[:,'38IC0'] = airpipette_data.loc[:,'38IC0'].values / 62415000\n",
    "airpipette_data.loc[:,'err 38IC0'] = airpipette_data.loc[:,'err 38IC0'].values / 62415000\n",
    "airpipette_data.loc[:,'36IC1'] = airpipette_data.loc[:,'36IC1'].values / 62415000\n",
    "airpipette_data.loc[:,'err 36IC1'] = airpipette_data.loc[:,'err 36IC1'].values / 62415000\n",
    "airpipette_data.loc[:,'36IC0'] = airpipette_data.loc[:,'36IC0'].values / 62415000\n",
    "airpipette_data.loc[:,'err 36IC0'] = airpipette_data.loc[:,'err 36IC0'].values / 62415000\n",
    "airpipette_data.loc[:,'36F'] = airpipette_data.loc[:,'36F'].values / 62415000\n",
    "airpipette_data.loc[:,'err 36F'] = airpipette_data.loc[:,'err 36F'].values / 62415000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > file Run4 e Run22 (file di misura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to change the file name of run4.txt, run22.txt, faradaysolo.txt see above\n",
    "\n",
    "# definire la lista con gli indici delle colonne \n",
    "column_names_run4 = ['40Ar F', 'err40Ar F', '38Ar IC0', 'err38Ar IC0', '36Ar IC1', 'err36Ar IC1','38Ar F', 'err38Ar F', '36Ar IC0', 'err36Ar IC0', '39Ar F', 'err39Ar F', '37Ar IC0', 'err37Ar IC0' , '35Cl IC1', 'err35Cl IC1', '39Ar IC0',  'err39Ar IC0',  '37Ar IC1', 'err37Ar IC1', 'gainF/IC0', 'err gainF/IC0' , 'gainIC0/IC1', 'err gainIC0/IC1', '40F/36IC1',  'err40F/36IC1',  '40F/36IC0' ,'err40F/36IC0', 'Run', 'Path']\n",
    "\n",
    "column_names_run22 = ['40Ar F', 'err40Ar F', '38Ar IC0', 'err38Ar IC0', '36Ar IC1', 'err36Ar IC1','38Ar F', 'err38Ar F', '36Ar IC0', 'err36Ar IC0', '39Ar F', 'err39Ar F', '37Ar IC0', 'err37Ar IC0' , '35Cl IC1', 'err35Cl IC1', 'gainIC0/IC1', 'err gainIC0/IC1' , '40F/36IC1',  'err40F/36IC1',  '40F/36IC0' ,'err40F/36IC0', 'Run', 'Path']\n",
    "\n",
    "column_names_faradaysolo = ['40Ar F', 'err40Ar F', '38Ar F', 'err38Ar F', '36Ar F', 'err36Ar F', '39Ar F', 'err39Ar F', '37Ar F', 'err37Ar F', 'Run', 'Path']\n",
    "\n",
    "# definire le colonne che contengono dati numerici\n",
    "colnames_numeric_4 = ['40Ar F', 'err40Ar F', '38Ar IC0', 'err38Ar IC0', '36Ar IC1', 'err36Ar IC1','38Ar F', 'err38Ar F', '36Ar IC0', 'err36Ar IC0', '39Ar F', 'err39Ar F', '37Ar IC0', 'err37Ar IC0' , '35Cl IC1', 'err35Cl IC1', '39Ar IC0',  'err39Ar IC0',  '37Ar IC1', 'err37Ar IC1', 'gainF/IC0', 'err gainF/IC0' , 'gainIC0/IC1', 'err gainIC0/IC1', '40F/36IC1',  'err40F/36IC1',  '40F/36IC0' ,'err40F/36IC0']  \n",
    " \n",
    "colnames_numeric_22 = ['40Ar F', 'err40Ar F', '38Ar IC0', 'err38Ar IC0', '36Ar IC1', 'err36Ar IC1','38Ar F', 'err38Ar F', '36Ar IC0', 'err36Ar IC0', '39Ar F', 'err39Ar F', '37Ar IC0', 'err37Ar IC0' , '35Cl IC1', 'err35Cl IC1', 'gainIC0/IC1', 'err gainIC0/IC1' , '40F/36IC1',  'err40F/36IC1',  '40F/36IC0' ,'err40F/36IC0']\n",
    "\n",
    "colnames_numeric_faradaysolo = column_names_faradaysolo[:-2]\n",
    "\n",
    "# importare i file run\n",
    "df_data_4 = pd.read_csv(file_path_4, header = None, index_col= False, names = column_names_run4, sep = '\\t|,', engine = 'python')\n",
    "df_data_22 = pd.read_csv(file_path_22, header = None, index_col= False, names = column_names_run22, sep = '\\t|,', engine = 'python')\n",
    "df_data_faradaysolo = pd.read_csv(file_path_faradaysolo, header = None, index_col= False, names = column_names_faradaysolo, sep = '\\t|,', engine = 'python')\n",
    "\n",
    "# eliminare i caratteri \"{}\" dalle colonne\n",
    "df_data_4 = df_data_4.replace([\"{\", \"}\"], [\"\", \"\"], regex=True)\n",
    "df_data_22 = df_data_22.replace([\"{\", \"}\"], [\"\", \"\"], regex=True)\n",
    "df_data_faradaysolo = df_data_faradaysolo.replace([\"{\", \"}\"], [\"\", \"\"], regex=True)\n",
    "\n",
    "# convertire tutte le colonne del dataframe df_data_4 a numeric (float64)\n",
    "for i in colnames_numeric_4:\n",
    "    df_data_4[i] = pd.to_numeric(df_data_4[i])\n",
    "\n",
    "# convertire tutte le colonne del dataframe df_data_22 a numeric (float64)\n",
    "for i in colnames_numeric_22:\n",
    "    df_data_22[i] = pd.to_numeric(df_data_22[i])\n",
    "\n",
    "# convertire tutte le colonne del dataframe df_data_faradaysolo a numeric (float64)\n",
    "for i in colnames_numeric_faradaysolo:\n",
    "    df_data_faradaysolo[i] = pd.to_numeric(df_data_faradaysolo[i])\n",
    "\n",
    "df_data = pd.concat([df_data_4, df_data_22, df_data_faradaysolo], axis=0)\n",
    "\n",
    "# dividere la colonna 'Run' in due colonne: nome del run e data/ora\n",
    "run_split = df_data['Run'].str.split(\" run on \")\n",
    "\n",
    "# formattare la colonna con il nome del run (del campione) in una serie pandas e associarle un nome \n",
    "run_name = run_split.str[0]\n",
    "run_name = run_name.replace([\"'\"], [\"\"], regex=True)\n",
    "run_name.name = 'Run_Name'\n",
    "\n",
    "# formattare la colonna con il numero del run \n",
    "run_number = df_data['Path'].str.split('.').str[0]\n",
    "run_number = run_number.str.split('_').str[-1]\n",
    "run_number.name= 'Run_Number'\n",
    "run_number = pd.to_numeric(run_number)\n",
    "\n",
    "# formattare la colonna con la data e l'ora in una serie pandas e associarle un nome, convertire il dato in datetime64\n",
    "dataora = run_split.str[1]\n",
    "dataora.name = 'Date_Time'\n",
    "dataora = pd.to_datetime(dataora)\n",
    "\n",
    "# concatenare le nuove colonne all'inizio del dataframe df_data\n",
    "df_data = pd.concat([run_name, run_number, dataora, df_data], axis = 1)\n",
    "\n",
    "# eliminare la colonna 'Run' (non più utilizzata)\n",
    "df_data.drop('Run',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrare i dati per numero run  per selezionare un solo campione\n",
    "#### Verificare correttezza della selezione nel dataframe visualizzato !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   > df_data:\n",
      "         Run_Name  Run_Number           Date_Time    40Ar F  err40Ar F  \\\n",
      "0   Q5C.3a Step 1       13537 2023-03-09 10:23:00  0.495035   0.000190   \n",
      "1   Q5C.3a Step 2       13538 2023-03-09 10:40:00  0.288700   0.000110   \n",
      "2   Q5C.3a Step 3       13539 2023-03-09 10:56:00  0.229499   0.000085   \n",
      "3   Q5C.3a Step 4       13540 2023-03-09 11:12:00  0.600377   0.000270   \n",
      "4   Q5C.3a Step 5       13541 2023-03-09 11:28:00  1.220850   0.000480   \n",
      "5   Q5C.3a Step 6       13542 2023-03-09 11:46:00  1.831960   0.000670   \n",
      "6   Q5C.3a Step 7       13543 2023-03-09 12:01:00  3.064380   0.001100   \n",
      "7   Q5C.3a Step 8       13544 2023-03-09 12:16:00  4.809840   0.002200   \n",
      "8   Q5C.3a Step 9       13545 2023-03-09 12:34:00  2.708200   0.001300   \n",
      "9  Q5C.3a Step 10       13546 2023-03-09 12:54:00  2.015280   0.000900   \n",
      "\n",
      "   38Ar IC0   err38Ar IC0  36Ar IC1   err36Ar IC1    38Ar F  ...  \\\n",
      "0  0.000236  3.400000e-07  0.001403  9.800000e-07  0.000368  ...   \n",
      "1  0.000133  3.200000e-07  0.000700  7.400000e-07  0.000172  ...   \n",
      "2  0.000095  2.400000e-07  0.000220  3.200000e-07  0.000150  ...   \n",
      "3  0.000177  4.000000e-07  0.000174  3.400000e-07  0.000289  ...   \n",
      "4  0.000212  3.700000e-07  0.000166  3.300000e-07  0.000334  ...   \n",
      "5  0.000229  4.600000e-07  0.000119  4.000000e-07  0.000391  ...   \n",
      "6  0.000315  4.300000e-07  0.000138  3.900000e-07  0.000537  ...   \n",
      "7  0.000387  6.500000e-07  0.000198  5.700000e-07  0.000714  ...   \n",
      "8  0.000184  3.900000e-07  0.000162  5.500000e-07  0.000343  ...   \n",
      "9  0.000220  3.900000e-07  0.000417  6.800000e-07  0.000392  ...   \n",
      "\n",
      "   err gainIC0/IC1  40F/36IC1  err40F/36IC1  40F/36IC0  err40F/36IC0  \\\n",
      "0          0.00091    352.738          0.28    444.650          0.44   \n",
      "1          0.00130    412.530          0.46    518.703          0.69   \n",
      "2          0.00190   1044.690          1.60   1302.920          2.50   \n",
      "3          0.00250   3450.670          6.90   4253.250         11.00   \n",
      "4          0.00280   7332.540         15.00   8966.090         26.00   \n",
      "5          0.00400  15431.600         52.00  18731.700         67.00   \n",
      "6          0.00350  22236.900         63.00  27040.700         88.00   \n",
      "7          0.00360  24287.300         71.00  30063.900        100.00   \n",
      "8          0.00420  16748.300         58.00  20231.200         75.00   \n",
      "9          0.00200   4832.200          8.20   5903.330         11.00   \n",
      "\n",
      "                                                Path  36Ar F  err36Ar F  \\\n",
      "0   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "1   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "2   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "3   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "4   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "5   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "6   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "7   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "8   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "9   Raw data stored in - C:\\Nu Noble\\Instrument S...     NaN        NaN   \n",
      "\n",
      "   37Ar F  err37Ar F  \n",
      "0     NaN        NaN  \n",
      "1     NaN        NaN  \n",
      "2     NaN        NaN  \n",
      "3     NaN        NaN  \n",
      "4     NaN        NaN  \n",
      "5     NaN        NaN  \n",
      "6     NaN        NaN  \n",
      "7     NaN        NaN  \n",
      "8     NaN        NaN  \n",
      "9     NaN        NaN  \n",
      "\n",
      "[10 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "df_data = df_data.loc[df_data['Run_Number'].between(run_start,run_end)]\n",
    "\n",
    "df_data.reset_index(drop=True, inplace=True)\n",
    "df_data.sort_values('Date_Time', axis=0, ascending=True, inplace=True, kind='quicksort', na_position='last')\n",
    "df_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\n   > df_data:\")\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   > calibration_data:\n",
      "       Run_Name  Run_Number           Date_Time      40F  err 40F     38IC0  \\\n",
      "60  Sample Name       13507 2023-03-07 10:46:00  2.38578   0.0011  0.001041   \n",
      "\n",
      "    err 38IC0     36IC1  err 36IC1     36IC0  err 36IC0       36F   err 36F  \\\n",
      "60   0.000001  0.007128   0.000004  0.005702   0.000005  0.008096  0.000012   \n",
      "\n",
      "    40F/36F  err 40F/36F                                               Path  \n",
      "60   294.68         0.47   Raw data stored in - C:\\Nu Noble\\Instrument S...  \n"
     ]
    }
   ],
   "source": [
    "# opzione selezione automatica della calibrazione più recente disponibile tra quelle più vecchie della misura\n",
    "sample_min = min(df_data['Date_Time'].to_list())\n",
    "older_calibration_df = airpipette_data[airpipette_data['Date_Time'] < sample_min]\n",
    "data_w = max(older_calibration_df['Date_Time'].to_list())\n",
    "\n",
    "airpipette_data_filtered = airpipette_data[airpipette_data['Date_Time'] == data_w]\n",
    "calibration_data = deepcopy(airpipette_data_filtered)\n",
    "print(\"\\n\\n   > calibration_data:\")\n",
    "print(calibration_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCOLO GAIN F/ICO ISOTOPO 39Ar\n",
    "df_data.loc[:,'F/IC0_39Ar']= df_data['39Ar F'].values/df_data['39Ar IC0'].values\n",
    "\n",
    "#df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea cartella specifica per ogni campione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genera una variabile che registra la data di analisi del campione\n",
    "\n",
    "date_analysis = df_data.iat[0, 2]\n",
    "\n",
    "#crea le cartelle dove vengono salvati i file di output\n",
    "\n",
    "directory_sample = \"Results/\" + date_analysis.strftime('%Y-%m-%d') + ' ' + sample_name\n",
    "\n",
    "directory_sample_plot = directory_sample + \"/\" + sample_name + \"_plots\"\n",
    "\n",
    "os.makedirs(directory_sample, exist_ok=True)\n",
    "os.makedirs(directory_sample_plot, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operazioni derivate dal file di calibrazione triplo36 (fogli Excel airpipette_data e sample_data)\n",
    "#### Per calcolare 1sig_rel (errore relativo) = err_abs / _Ar  (err_abs corrisponde all'errore che misura lo spettrometro)\n",
    "#### 1sig_abs = errore assoluto, 1sig_rel = errore relativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolare sig_rel 36_IC0\n",
    "value_err36IC0 = float(calibration_data['err 36IC0'].values)\n",
    "value_36IC0 = float(calibration_data['36IC0'].values)\n",
    "sig_rel_36IC0 = float(value_err36IC0 / value_36IC0)\n",
    "#print ('1sig_rel_36IC0: ', sig_rel_36IC0)\n",
    "\n",
    "# calcolare sig_rel 36_IC1\n",
    "value_err36IC1 = float(calibration_data['err 36IC1'].values)\n",
    "value_36IC1 = float(calibration_data['36IC1'].values)\n",
    "sig_rel_36IC1 = float(value_err36IC1 / value_36IC1)\n",
    "#print ('1sig_rel_36IC1: ', sig_rel_36IC1)\n",
    "\n",
    "# calcolare sig_rel 36_F\n",
    "value_err36F = float(calibration_data['err 36F'].values)\n",
    "value_36F = float(calibration_data['36F'].values)\n",
    "sig_rel_36F = float(value_err36F / value_36F)\n",
    "#print ('1sig_rel_36F: ', sig_rel_36F)\n",
    "\n",
    "# calcolare sig_rel 40F/36F\n",
    "value_err40F_36F = float(calibration_data['err 40F/36F'].values)\n",
    "value_40F_36F = float(calibration_data['40F/36F'].values)\n",
    "sig_rel_40F_36F = float(value_err40F_36F / value_40F_36F)\n",
    "#print ('1sig_rel_40F/36F: ', sig_rel_40F_36F)\n",
    "\n",
    "# calcolare GAIN_F/IC0\n",
    "value_36F = float(calibration_data['36F'].values)\n",
    "value_36IC0 = float(calibration_data['36IC0'].values)\n",
    "gain_F_IC0 = float(value_36F / value_36IC0)\n",
    "#print ('gain F/IC0: ', gain_F_IC0)\n",
    "\n",
    "# calcolare sig_abs GAIN_F/IC0\n",
    "sig_abs_F_ICO = gain_F_IC0 * (pow(sig_rel_36IC0, 2) + pow(sig_rel_36F, 2))**(1/2)\n",
    "#print ('sig_abs_F/ICO: ', sig_abs_F_ICO)\n",
    "\n",
    "# calcolare GAIN_F/IC1\n",
    "value_36F = float(calibration_data['36F'].values)\n",
    "value_36IC1 = float(calibration_data['36IC1'].values)\n",
    "gain_F_IC1 = float(value_36F / value_36IC1)\n",
    "#print ('gain F/IC1: ', gain_F_IC1)\n",
    "\n",
    "# calcolare sig_abs GAIN_F/IC1\n",
    "sig_abs_F_IC1 = gain_F_IC1 * (pow(sig_rel_36IC1, 2) + pow(sig_rel_36F, 2))**(1/2)\n",
    "#print ('sig_abs_F/IC1: ', sig_abs_F_IC1)\n",
    "\n",
    "# calcolare 36IC0 correzione gain\n",
    "corr_gain_36IC0 = value_36IC0 * gain_F_IC0\n",
    "#print ('corr_gain_36IC0: ', corr_gain_36IC0) \n",
    "\n",
    "# calcolare 40/36 correzione\n",
    "value_40F = float(calibration_data['40F'].values)\n",
    "corr_40_36 = (value_40F) / corr_gain_36IC0\n",
    "#print ('corr_40_36: ', corr_40_36)\n",
    "\n",
    "# calcolare sig_abs 40/36 correzione\n",
    "sig_abs_40_36 = corr_40_36 * (pow(sig_rel_36F, 2) + pow(calibration_data['err 40F'].values / calibration_data['40F'].values, 2))**(1/2)\n",
    "#print ('sig_abs_40/36: ', sig_abs_40_36)\n",
    "\n",
    "# calcolare source frax\n",
    "source_frax = float(corr_40_36 / 298.56)\n",
    "#print ('source_frax: ', source_frax)\n",
    "\n",
    "# calcolare sig_abs source frax\n",
    "sig_abs_source_frax = source_frax * (sig_abs_40_36 / corr_40_36)\n",
    "#print ('sig_abs_source_frax: ', sig_abs_source_frax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definire tutti i parametri delle tabelle (A) e (B) del file Excel CalcolAr\n",
    "### Tabella: BACKGROUND SPECTROMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# to change the background value measurements, see above\n",
    "\n",
    "background_spectrometer_df = pd.DataFrame.from_dict(background_spectrometer_dict, orient='index')\n",
    "background_spectrometer_df.columns = ['value', 'relative error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabella: IRRADIATIONS CONSTANTS \n",
    "#### (NON SONO DA MODIFICARE, valori costanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to change the irradiation constants, see above\n",
    "\n",
    "irradiations_constants_df = pd.DataFrame.from_dict(irradiations_constants_dict, orient='index')\n",
    "irradiations_constants_df.columns = ['value', 'relative error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabella: IRRADIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change sample weight, J factors, and sensitivity, see above\n",
    "\n",
    "# i seguenti calcoli vengono svolti dal codice\n",
    "\n",
    "# i gain_F_IC1 sono già stati calcolati precedentemente \n",
    "\n",
    "measured_40Ar_36Ar_pipettes_sensor36 = \"IC1\"\n",
    "measured_40Ar_36Ar_pipettes = calibration_data['40F'].values / calibration_data['36IC1'].values\n",
    "\n",
    "gain_rel_uncertainty_errors = sig_rel_40F_36F\n",
    "gain_rel_uncertainty = gain_rel_uncertainty_errors / gain_F_IC1\n",
    "\n",
    "# TODO this is just calculating calibration_data[36F] exactly (dividing and multiplying the same numbers)\n",
    "gain_corrected_40Ar_36Ar_pipettes = measured_40Ar_36Ar_pipettes / gain_F_IC1\n",
    "gain_corrected_40Ar_36Ar_pipettes_errors = gain_corrected_40Ar_36Ar_pipettes / irradiations_constants_df.loc['Atmospheric Ratio', 'value']\n",
    "\n",
    "pipette_rel_uncertainty = sig_abs_source_frax  \n",
    "total_fractionation_uncertainty = sig_abs_source_frax\n",
    "\n",
    "irradiations_dict = {'Sample weight [g]': [sample_weight, 0],\n",
    "                     'J factor': [J_factor, J_factor_errors],\n",
    "                     'Sensitivity (mL/mV)': [sensitivity, 0],\n",
    "                     'Gain F/IC1': [gain_F_IC1, 0],\n",
    "                     'Gain rel uncertainty': [gain_rel_uncertainty, gain_rel_uncertainty_errors],\n",
    "                     'Gain corrected 40Ar/36Ar pipettes': [gain_corrected_40Ar_36Ar_pipettes[0], gain_corrected_40Ar_36Ar_pipettes_errors[0]], \n",
    "                     'Pipette rel uncertainty': [pipette_rel_uncertainty[0], 0],\n",
    "                     'Total fractionation uncertainty': [total_fractionation_uncertainty[0], 0]} \n",
    "\n",
    "irradiations_df = pd.DataFrame.from_dict(irradiations_dict, orient='index')\n",
    "irradiations_df.columns = ['value', 'relative error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operazioni foglio Excel CalcolAr = file PyCalcolAr\n",
    "#### Le operazione verranno aggiunte in un unico dataframe di risultati simili a quelle del file Excel CalcolAr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creare il dataframe input_data \n",
    "input_data_df = pd.DataFrame() \n",
    "\n",
    "# colonna Time costante \n",
    "input_data_df.loc[:, 'Time'] = pd.Series(1 for k in range(0, len(df_data.index)))\n",
    "\n",
    "# 6° cella del codice (DA MODIFICARE MANUALMENTE DALL'UTENTE)\n",
    "input_data_df.loc[:, 'Delay'] = pd.Series(delay for k in range(0, len(df_data.index)))\n",
    "\n",
    "#print(input_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input = online Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_data_df.loc[:, '40Ar'] = df_data.loc[:, '40Ar F'].values * 1000\n",
    "input_data_df.loc[:, 'err40Ar'] = df_data.loc[:, 'err40Ar F'].values * 1000\n",
    "\n",
    "count_row = df_data.shape[0]\n",
    "\n",
    "for i in range (count_row):\n",
    "    if pd.isna(df_data.loc[i, '39Ar IC0']):\n",
    "        input_data_df.loc[i, '39Ar'] = df_data.loc[i, '39Ar F'] * 1000\n",
    "        input_data_df.loc[i, 'err39Ar'] = df_data.loc[i, 'err39Ar F']* 1000\n",
    "    elif (df_data.loc[i, '39Ar F'])>= 0.003:\n",
    "        input_data_df.loc[i, '39Ar'] = df_data.loc[i, '39Ar F'] * 1000\n",
    "        input_data_df.loc[i, 'err39Ar'] = df_data.loc[i, 'err39Ar F']* 1000\n",
    "    else:\n",
    "        input_data_df.loc[i, '39Ar'] = df_data.loc[i, '39Ar IC0'] * gain_F_IC0 * 1000\n",
    "        input_data_df.loc[i, 'err39Ar'] = df_data.loc[i, 'err39Ar IC0']* gain_F_IC0 * 1000\n",
    "\n",
    "for i in range (count_row):\n",
    "    if pd.isna(df_data.loc[i, '38Ar IC0']):\n",
    "        input_data_df.loc[i, '38Ar'] = df_data.loc[i, '38Ar F'] * 1000\n",
    "        input_data_df.loc[i, 'err38Ar'] = df_data.loc[i, 'err38Ar F'] * 1000\n",
    "    else:\n",
    "        input_data_df.loc[i, '38Ar'] = df_data.loc[i, '38Ar IC0'] * gain_F_IC0 * 1000\n",
    "        input_data_df.loc[i, 'err38Ar'] = df_data.loc[i, 'err38Ar IC0'] * gain_F_IC0 * 1000\n",
    "\n",
    "for i in range (count_row):\n",
    "    if pd.isna(df_data.loc[i, '37Ar IC0']):\n",
    "        input_data_df.loc[i, '37Ar'] = df_data.loc[i, '37Ar F'] * 1000\n",
    "        input_data_df.loc[i, 'err37Ar'] = df_data.loc[i, 'err37Ar F'] * 1000\n",
    "    else:\n",
    "        input_data_df.loc[i, '37Ar'] = df_data.loc[i, '37Ar IC0'] * gain_F_IC0 * 1000\n",
    "        input_data_df.loc[i, 'err37Ar'] = df_data.loc[i, 'err37Ar IC0'] * gain_F_IC0 * 1000\n",
    "    #elif (df_data.loc[i, '37Ar IC1'])<= 0.001:\n",
    "       # input_data_df.loc[i, '37Ar'] = df_data.loc[i, '37Ar IC0'] * gain_F_IC0 * 1000\n",
    "      #  input_data_df.loc[i, 'err37Ar'] = df_data.loc[i, 'err37Ar IC0'] * gain_F_IC0 * 1000    \n",
    "   # else:\n",
    "        #input_data_df.loc[i, '37Ar'] = df_data.loc[i, '37Ar IC1'] * df_data.loc[i, 'gainIC0/IC1'] * 1000\n",
    "        #input_data_df.loc[i, 'err37Ar'] = df_data.loc[i, 'err37Ar IC1']* df_data.loc[i, 'gainIC0/IC1']  * 1000\n",
    "       # print(\"wanrning verificare il gain: \", df_data.loc[i, 'gainIC0/IC1'])\n",
    "   # print('i = ', i, ' - 37Ar IC0= ', input_data_df.loc[i, '37Ar IC0'], ' - 37Ar IC1= ', input_data_df.loc[i, '37Ar IC1'], ' - 37Ar = ', input_data_df.loc[i, '37Ar'])\n",
    "\n",
    "for i in range (count_row):\n",
    "    if pd.isna(df_data.loc[i, '36Ar IC1']):\n",
    "        input_data_df.loc[i, '36Ar'] = df_data.loc[i, '36Ar F'] * 1000\n",
    "        input_data_df.loc[i, 'err36Ar'] = df_data.loc[i, 'err36Ar F'] * 1000\n",
    "    else:\n",
    "        input_data_df.loc[i, '36Ar'] = df_data.loc[i, '36Ar IC1'] * gain_F_IC1 * 1000\n",
    "        input_data_df.loc[i, 'err36Ar'] = df_data.loc[i, 'err36Ar IC1'] * gain_F_IC1 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measured values corrected for mass spectrometer background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_mL_39Ar:  4.755435643982124e-09\n",
      "   Time  Delay      40Ar  err40Ar       39Ar   err39Ar      38Ar   err38Ar  \\\n",
      "0     1     62   495.035    0.190   0.676834  0.000895  0.335004  0.000483   \n",
      "1     1     62   288.700    0.110   1.529462  0.001292  0.189017  0.000454   \n",
      "2     1     62   229.499    0.085   4.003970  0.014000  0.134548  0.000341   \n",
      "3     1     62   600.377    0.270  12.186100  0.016000  0.251651  0.000568   \n",
      "4     1     62  1220.850    0.480  19.052600  0.016000  0.301136  0.000525   \n",
      "5     1     62  1831.960    0.670  23.454300  0.019000  0.325562  0.000653   \n",
      "6     1     62  3064.380    1.100  31.639700  0.019000  0.447392  0.000611   \n",
      "7     1     62  4809.840    2.200  37.279900  0.020000  0.549017  0.000923   \n",
      "8     1     62  2708.200    1.300  15.771900  0.015000  0.261379  0.000554   \n",
      "9     1     62  2015.280    0.900  13.477100  0.018000  0.312620  0.000554   \n",
      "\n",
      "       37Ar   err37Ar  ...  Age+2error  Age-2error      Ca/K  err_Ca/K  \\\n",
      "0  0.019883  0.000142  ...   35.491934   31.155143  0.134876  0.011869   \n",
      "1  0.038445  0.000185  ...   32.006139   30.942704  0.139283  0.005262   \n",
      "2  0.075806  0.000270  ...   34.494432   33.984776  0.114368  0.002075   \n",
      "3  0.263578  0.000525  ...   39.100018   38.866234  0.138630  0.000753   \n",
      "4  0.194968  0.000469  ...   53.467148   53.244715  0.065036  0.000457   \n",
      "5  0.156574  0.000341  ...   66.558410   66.292929  0.042092  0.000357   \n",
      "6  0.166614  0.000483  ...   82.688111   82.413675  0.033282  0.000274   \n",
      "7  0.261674  0.000554  ...  109.476960  109.111273  0.044969  0.000242   \n",
      "8  0.276849  0.000497  ...  143.548965  142.884317  0.112622  0.000572   \n",
      "9  0.340670  0.000554  ...  119.613604  118.899737  0.162870  0.000712   \n",
      "\n",
      "       Cl/K  err_Cl/K     39/40  err39/40     36/40      err36/40  \n",
      "0  0.009082  0.000468  0.001355  0.000002  0.003176  5.605444e-06  \n",
      "1  0.003033  0.000309  0.005270  0.000006  0.002714  5.272232e-06  \n",
      "2  0.002019  0.000127  0.017393  0.000062  0.001068  2.410670e-06  \n",
      "3  0.001247  0.000036  0.020242  0.000029  0.000322  8.591227e-07  \n",
      "4  0.000598  0.000019  0.015562  0.000016  0.000152  4.073269e-07  \n",
      "5  0.000394  0.000017  0.012765  0.000012  0.000072  2.818279e-07  \n",
      "6  0.000468  0.000009  0.010294  0.000008  0.000050  1.702943e-07  \n",
      "7  0.000538  0.000009  0.007727  0.000006  0.000046  1.554541e-07  \n",
      "8  0.000675  0.000026  0.005805  0.000007  0.000066  2.579014e-07  \n",
      "9  0.001083  0.000027  0.006665  0.000010  0.000231  5.394173e-07  \n",
      "\n",
      "[10 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "results_data = input_data_df\n",
    "\n",
    "results_data.loc[:,'40Ar BC'] = results_data.loc[:, '40Ar'].values - (results_data.loc[:, '39Ar'].values * irradiations_constants_df.loc['Interference 40K', 'value']) - background_spectrometer_df.loc['Background 40Ar', 'value']\n",
    "results_data.loc[:,'1sigma_abs40'] = (pow(results_data.loc[:, 'err40Ar'].values, 2) + pow(background_spectrometer_df.loc['Background 40Ar', 'value'] * background_spectrometer_df.loc['Background 40Ar', 'relative error'], 2))**(1/2)\n",
    "results_data.loc[:,'1sigma_rel40'] = results_data.loc[:,'1sigma_abs40'].values / results_data.loc[:,'40Ar BC'].values\n",
    "\n",
    "results_data.loc[:,'39Ar BC'] = results_data.loc[:, '39Ar'].values - background_spectrometer_df.loc['Background 39Ar', 'value']\n",
    "results_data.loc[:,'1sigma_abs39'] = (pow(results_data.loc[:, 'err39Ar'].values, 2) + pow(background_spectrometer_df.loc['Background 39Ar', 'value'] * background_spectrometer_df.loc['Background 39Ar', 'relative error'], 2))**(1/2)\n",
    "results_data.loc[:,'1sigma_rel39'] = results_data.loc[:,'1sigma_abs39'].values / results_data.loc[:,'39Ar BC'].values\n",
    "\n",
    "results_data.loc[:,'38Ar BC'] = results_data.loc[:, '38Ar'].values - background_spectrometer_df.loc['Background 38Ar', 'value']\n",
    "results_data.loc[:,'1sigma_abs38'] = (pow(results_data.loc[:, 'err38Ar'].values, 2) + pow(background_spectrometer_df.loc['Background 38Ar', 'value'] * background_spectrometer_df.loc['Background 38Ar', 'relative error'], 2))**(1/2)\n",
    "results_data.loc[:,'1sigma_rel38'] = results_data.loc[:,'1sigma_abs38'].values / results_data.loc[:,'38Ar BC'].values\n",
    "\n",
    "results_data.loc[:,'37Ar BC'] = results_data.loc[:, '37Ar'].values - background_spectrometer_df.loc['Background 37Ar', 'value']\n",
    "results_data.loc[:,'1sigma_abs37'] = (pow(results_data.loc[:, 'err37Ar'].values, 2) + pow(background_spectrometer_df.loc['Background 37Ar', 'value'] * background_spectrometer_df.loc['Background 37Ar', 'relative error'], 2))**(1/2)\n",
    "results_data.loc[:,'1sigma_rel37'] = results_data.loc[:,'1sigma_abs37'].values / results_data.loc[:,'37Ar BC'].values\n",
    "\n",
    "results_data.loc[:,'36Ar BC'] = results_data.loc[:, '36Ar'].values - background_spectrometer_df.loc['Background 36Ar', 'value']\n",
    "results_data.loc[:,'1sigma_abs36'] = (pow(results_data.loc[:, 'err36Ar'].values, 2) + pow(background_spectrometer_df.loc['Background 36Ar', 'value'] * background_spectrometer_df.loc['Background 36Ar', 'relative error'], 2))**(1/2)\n",
    "results_data.loc[:,'1sigma_rel36'] = results_data.loc[:,'1sigma_abs36'].values / results_data.loc[:,'36Ar BC'].values\n",
    "\n",
    "# 37Ar decay\n",
    "\n",
    "results_data.loc[:,'Decay Factor'] = (irradiations_constants_df.loc['Lambda Ar37 [1/d]', 'value'] * results_data.loc[0, 'Time'] * math.exp(irradiations_constants_df.loc['Lambda Ar37 [1/d]', 'value'] * results_data.loc[0, 'Delay'])) / (1-math.exp((-1) * irradiations_constants_df.loc['Lambda Ar37 [1/d]', 'value'] * 1))\n",
    "\n",
    "# Multiplier for Fract Corr: si moltiplichi l'isotopo leggero per il fattore\n",
    "\n",
    "results_data.loc[:,'Mult 4amu'] = irradiations_df.loc['Gain corrected 40Ar/36Ar pipettes', 'relative error']\n",
    "results_data.loc[:,'Mult 2amu'] = (results_data.loc[:,'Mult 4amu'].values + 1) / 2\n",
    "results_data.loc[:,'Mult 1amu'] = (results_data.loc[:,'Mult 4amu'].values + 3) / 4\n",
    "\n",
    "# Bg + Fract + Decay Corrected\n",
    "results_data.loc[:,'Ar36tot'] = results_data.loc[:,'36Ar BC'].values * results_data.loc[:,'Mult 4amu'].values\n",
    "results_data.loc[:,'1sigRel36tot'] = (pow(results_data.loc[:,'1sigma_rel36'].values, 2) + pow(irradiations_df.loc['Total fractionation uncertainty', 'value'], 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'Ar38tot'] = results_data.loc[:,'38Ar BC'].values * results_data.loc[:,'Mult 2amu'].values\n",
    "results_data.loc[:,'1sigRel38tot'] = (pow(results_data.loc[:,'1sigma_rel38'].values, 2) + 0.25 * pow(irradiations_df.loc['Total fractionation uncertainty', 'value'], 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'Ar39tot'] = results_data.loc[:,'39Ar BC'].values * results_data.loc[:,'Mult 1amu'].values\n",
    "results_data.loc[:,'1sigRel39tot'] = (pow(results_data.loc[:,'1sigma_rel39'].values, 2) + 0.0625 * pow(irradiations_df.loc['Total fractionation uncertainty', 'value'], 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'Ar37day0'] = results_data.loc[:, 'Decay Factor'].values * results_data.loc[:,'37Ar BC'].values * (results_data.loc[:,'Mult 4amu'].values * results_data.loc[:,'Mult 2amu'])\n",
    "results_data.loc[:,'1sigRel37corr'] = (pow(results_data.loc[:,'1sigma_rel37'].values, 2) + pow(irradiations_df.loc['Total fractionation uncertainty', 'value'], 2) * 9/ 16)**(1/2)\n",
    "\n",
    "# Interference Corrected\n",
    "results_data.loc[:,'Ar39Ca'] = results_data.loc[:,'Ar37day0'].values * (irradiations_constants_df.loc['(39Ar/37Ar) Ca', 'value'])\n",
    "results_data.loc[:,'1sigRel39Ca'] = (pow(results_data.loc[:,'1sigRel37corr'].values, 2) + 0.000225)**(1/2)\n",
    "results_data.loc[:,'1sigAbs39Ca'] = results_data.loc[:,'1sigRel39Ca'].values * results_data.loc[:,'Ar39Ca'].values\n",
    "\n",
    "results_data.loc[:,'Ar39K'] = results_data.loc[:,'Ar39tot'].values - results_data.loc[:,'Ar39Ca'].values\n",
    "results_data.loc[:,'1sigAbs39K'] = (pow(results_data.loc[:,'1sigAbs39Ca'].values,2) + pow(results_data.loc[:,'1sigRel39tot'].values * results_data.loc[:,'Ar39tot'].values, 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'Ar36Ca'] = results_data.loc[:,'Ar37day0'].values * irradiations_constants_df.loc['(36Ar/37Ar) Ca', 'value']\n",
    "results_data.loc[:,'1sigRel36Ca'] = (pow(results_data.loc[:,'1sigRel37corr'].values, 2) + 0.000225)**(1/2) \n",
    "results_data.loc[:,'1sigAbs36Ca'] = results_data.loc[:,'1sigRel36Ca'].values * results_data.loc[:,'Ar36Ca'].values\n",
    "\n",
    "results_data.loc[:,'Ar36Atm'] = results_data.loc[:,'Ar36tot'].values - results_data.loc[:,'Ar36Ca'].values\n",
    "results_data.loc[:,'1sigAbs36Atm'] = (pow(results_data.loc[:,'1sigAbs36Ca'].values,2) + pow(results_data.loc[:,'1sigRel36tot'].values * results_data.loc[:,'Ar36tot'].values, 2))**(1/2)\n",
    "results_data.loc[:,'1sigRel36Atm'] = results_data.loc[:,'1sigAbs36Atm'].values / results_data.loc[:,'Ar36Atm'].values\n",
    "\n",
    "results_data.loc[:,'Ar40Atm'] = results_data.loc[:,'Ar36Atm'].values * irradiations_constants_df.loc['Atmospheric Ratio', 'value']\n",
    "results_data.loc[:,'1sigAbs40Atm'] = results_data.loc[:,'Ar40Atm'].values * results_data.loc[:,'1sigRel36Atm'].values\n",
    "\n",
    "results_data.loc[:, 'Ar40*'] = results_data.loc[:,'40Ar BC'].values - results_data.loc[:,'Ar40Atm'].values\n",
    "results_data.loc[:,'1sigAbs40*'] = (pow(results_data.loc[:,'1sigma_abs40'].values, 2) + pow(results_data.loc[:,'1sigAbs40Atm'].values, 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'rendimento rad'] = results_data.loc[:, 'Ar40*'].values / results_data.loc[:,'40Ar BC'].values\n",
    "results_data.loc[:,'error magnif'] = (1 /results_data.loc[:,'rendimento rad'].values - 1)\n",
    "results_data.loc[:,'error36*magnif'] = results_data.loc[:,'1sigRel36Atm'].values * results_data.loc[:,'error magnif'].values\n",
    "\n",
    "results_data.loc[:,'1sigRel40*'] = results_data.loc[:,'1sigAbs40*'].values / results_data.loc[:, 'Ar40*']\n",
    "\n",
    "results_data.loc[:,'Ar38Cl'] = results_data.loc[:,'Ar38tot'].values - results_data.loc[:,'Ar39K'].values / 95 - results_data.loc[:,'Ar36Atm'].values * 0.1847 - results_data.loc[:,'Ar37day0'].values * 0.00027\n",
    "results_data.loc[:,'1sigAbs38Cl'] = (pow(results_data.loc[:,'1sigRel38tot'].values, 2) + pow((results_data.loc[:,'1sigAbs39K'].values / 85), 2) + pow((results_data.loc[:,'1sigAbs36Atm'].values * 0.18855), 2) + pow((results_data.loc[:,'1sigRel37corr'].values * results_data.loc[:,'Ar37day0'].values * 0.00027), 2))**(1/2)\n",
    "results_data.loc[:,'1sigRel38Cl'] = results_data.loc[:,'1sigAbs38Cl'].values / results_data.loc[:,'Ar38Cl'].values\n",
    "\n",
    "# RESULTS\n",
    "\n",
    "results_data.loc[:,'40Ar_total'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:,'40Ar BC'].values\n",
    "results_data.loc[:,'err_40Ar'] = results_data.loc[:,'40Ar_total'].values * results_data.loc[:,'1sigma_rel40'].values\n",
    "\n",
    "results_data.loc[:,'40Ar*'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:, 'Ar40*'].values\n",
    "results_data.loc[:, 'err_40Ar*'] = results_data.loc[:,'1sigRel40*'].values * results_data.loc[:,'40Ar*'].values\n",
    "\n",
    "results_data.loc[:,'39_Ar'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:,'Ar39tot'].values\n",
    "results_data.loc[:,'err_39Ar'] = results_data.loc[:,'39_Ar'].values * results_data.loc[:,'1sigRel39tot'].values\n",
    "\n",
    "\n",
    "# inserire variabile cella BP3 = sommatoria colonne 39Ar (BP)\n",
    "total_mL_39Ar = results_data.loc[:,'39_Ar'].sum()\n",
    "print ('total_mL_39Ar: ', total_mL_39Ar)\n",
    "\n",
    "results_data.loc[:,'% 39Ar'] = 100 * (results_data.loc[:,'39_Ar'].values / total_mL_39Ar) \n",
    "\n",
    "results_data.loc[:,'38_Ar'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:,'Ar38tot'].values  \n",
    "results_data.loc[:,'err_38Ar'] = results_data.loc[:,'38_Ar'].values * results_data.loc[:,'1sigRel38tot'].values\n",
    "\n",
    "results_data.loc[:,'38Ar_Cl'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:,'Ar38Cl'].values\n",
    "results_data.loc[:,'err_38Cl'] = results_data.loc[:,'1sigRel38Cl'].values * results_data.loc[:,'38Ar_Cl'].values\n",
    "\n",
    "results_data.loc[:,'37_Ar'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:,'Ar37day0'].values\n",
    "results_data.loc[:,'err_37Ar'] = results_data.loc[:,'1sigRel37corr'].values *  results_data.loc[:,'37_Ar'].values\n",
    "\n",
    "results_data.loc[:,'36_Ar'] = irradiations_df.loc['Sensitivity (mL/mV)', 'value'] * results_data.loc[:,'Ar36tot'].values\n",
    "results_data.loc[:,'err_36Ar'] = results_data.loc[:,'1sigRel36tot'].values * results_data.loc[:,'36_Ar'].values\n",
    "\n",
    "results_data.loc[:,'Age'] = np.log(1 + (results_data.loc[:,'Ar40*'].values * irradiations_df.loc['J factor', 'value'] / results_data.loc[:,'Ar39K'].values)) / irradiations_constants_df.loc['Lambda Ar40 [1/Ma]', 'value']\n",
    "results_data.loc[:,'1sigma_err_Age'] = results_data.loc[:,'Age'].values * (pow(irradiations_df.loc['J factor', 'relative error'], 2)+ pow(results_data.loc[:,'1sigRel40*'].values, 2) + pow(results_data.loc[:,'1sigAbs39K'].values / results_data.loc[:,'Ar39K'].values, 2))**(1/2)\n",
    "results_data.loc[:,'Age+2error'] = results_data.loc[:,'Age'].values + 2 * results_data.loc[:,'1sigma_err_Age'].values\n",
    "results_data.loc[:,'Age-2error'] = results_data.loc[:,'Age'].values - 2 * results_data.loc[:,'1sigma_err_Age'].values  \n",
    "\n",
    "results_data.loc[:,'Ca/K'] =  results_data.loc[:,'Ar37day0'].values * (1.94 / results_data.loc[:,'Ar39K'].values) \n",
    "results_data.loc[:,'err_Ca/K'] = results_data.loc[:,'Ca/K'].values * (pow(results_data.loc[:,'1sigRel37corr'].values, 2) + pow(results_data.loc[:,'1sigAbs39K'].values / results_data.loc[:,'Ar39K'].values, 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'Cl/K'] = irradiations_constants_df.loc['Coefficient Cl/K', 'value'] * (results_data.loc[:,'38Ar_Cl'].values / results_data.loc[:,'39_Ar'].values)\n",
    "results_data.loc[:,'err_Cl/K'] = results_data.loc[:,'Cl/K'].values * (pow(results_data.loc[:,'1sigRel38Cl'].values, 2) + pow(results_data.loc[:,'1sigAbs39K'].values / results_data.loc[:,'Ar39K'].values, 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'39/40'] = results_data.loc[:,'Ar39K'].values / results_data.loc[:,'40Ar BC'].values\n",
    "results_data.loc[:,'err39/40'] = results_data.loc[:,'39/40'] * (pow(results_data.loc[:,'1sigma_rel40'].values, 2) + pow(results_data.loc[:,'1sigAbs39K'].values / results_data.loc[:,'Ar39K'].values, 2))**(1/2)\n",
    "\n",
    "results_data.loc[:,'36/40'] = (results_data.loc[:,'Ar36tot'].values - (results_data.loc[:,'Ar37day0'].values * irradiations_constants_df.loc['(36Ar/37Ar) Ca', 'value'])) / results_data.loc[:,'40Ar BC'].values\n",
    "results_data.loc[:,'err36/40'] = results_data.loc[:,'36/40'].values * (pow(results_data.loc[:,'1sigma_rel40'].values, 2) + pow(results_data.loc[:,'1sigRel36Atm'].values, 2))**(1/2)\n",
    "\n",
    "print(results_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea un dataframe di riassunto di dati di input e output ed esporta in .xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(directory_sample + \"/\" + sample_name + \"_results.xlsx\") as writer: \n",
    "    \n",
    "    irradiations_df.to_excel(writer, sheet_name='Irradiation')\n",
    "    irradiations_constants_df.to_excel(writer, sheet_name='Irradiation_constants')\n",
    "    calibration_data.to_excel(writer, sheet_name='Calibration')\n",
    "    results_data.to_excel(writer, sheet_name='Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione dei grafici (FOR SPECTRUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sheet \"plots_parameters\" from the sample_name_config.xlsx file\n",
    "\n",
    "df_config_plot_parameters = pd.read_excel(\n",
    "    io=config_path,\n",
    "    sheet_name='plot_parameters',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zoom_to_steps_str = df_config_plot_parameters.iat[1, 1]\n",
    "    zoom_to_steps_str_list = zoom_to_steps_str.split(',')\n",
    "    \n",
    "    zoom_to_steps = []\n",
    "    \n",
    "    for element_str in zoom_to_steps_str_list:\n",
    "        \n",
    "        element = int(element_str)\n",
    "        zoom_to_steps.append(element)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the variable \"steps_to_show\" to a list\n",
    "\n",
    "#zoom_to_steps_cl_k_age\n",
    "zoom_to_steps_str = df_config_plot_parameters.iat[1, 1]\n",
    "zoom_to_steps_str_list = zoom_to_steps_str.split(',')\n",
    "    \n",
    "zoom_to_steps_cl_k_age = []\n",
    "    \n",
    "for element_str in zoom_to_steps_str_list:\n",
    "        element = int(element_str)\n",
    "        zoom_to_steps_cl_k_age.append(element)\n",
    "        \n",
    "        \n",
    "# zoom_to_steps_ca_k_age\n",
    "zoom_to_steps_str = df_config_plot_parameters.iat[3, 1]\n",
    "zoom_to_steps_str_list = zoom_to_steps_str.split(',')\n",
    "    \n",
    "zoom_to_steps_ca_k_age = []\n",
    "    \n",
    "for element_str in zoom_to_steps_str_list:\n",
    "        element = int(element_str)\n",
    "        zoom_to_steps_ca_k_age.append(element)\n",
    "        \n",
    "# zoom_to_steps_ca_k_cl_k     \n",
    "zoom_to_steps_str = df_config_plot_parameters.iat[5, 1]\n",
    "zoom_to_steps_str_list = zoom_to_steps_str.split(',')\n",
    "    \n",
    "zoom_to_steps_ca_k_cl_k = []\n",
    "    \n",
    "for element_str in zoom_to_steps_str_list:\n",
    "        element = int(element_str)\n",
    "        zoom_to_steps_ca_k_cl_k.append(element)\n",
    "        \n",
    "# zoom_to_steps_spectrum \n",
    "\n",
    "zoom_to_steps_str = df_config_plot_parameters.iat[7, 1]\n",
    "zoom_to_steps_str_list = zoom_to_steps_str.split(',')\n",
    "    \n",
    "zoom_to_steps_spectrum = []\n",
    "    \n",
    "for element_str in zoom_to_steps_str_list:\n",
    "        element = int(element_str)\n",
    "        zoom_to_steps_spectrum.append(element)\n",
    "\n",
    "#show_labels_for_steps\n",
    "\n",
    "zoom_to_steps_str = df_config_plot_parameters.iat[8, 1]\n",
    "zoom_to_steps_str_list = zoom_to_steps_str.split(',')\n",
    "    \n",
    "show_labels_for_steps = []\n",
    "    \n",
    "for element_str in zoom_to_steps_str_list:\n",
    "        element = int(element_str)\n",
    "        show_labels_for_steps.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione che se usa dopo\n",
    "def point_plot(x_data, y_data, zoom_to_steps, color):\n",
    "    plt.plot(x_data, y_data,\n",
    "             marker= 'o', markersize = 8, markeredgecolor='black', markerfacecolor=color,\n",
    "             linestyle='dashed', linewidth=1, color='grey')\n",
    "    \n",
    "    ymin = y_data[zoom_to_steps].min()\n",
    "    ymax = y_data[zoom_to_steps].max()\n",
    "    plt.ylim(( ymin-(ymax-ymin)/8, ymax+(ymax-ymin)/8 ))\n",
    "\n",
    "    xmin = x_data[zoom_to_steps].min()\n",
    "    xmax = x_data[zoom_to_steps].max()\n",
    "    plt.xlim(( xmin-(xmax-xmin)/8, xmax+(xmax-xmin)/8 ))\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    # etichetta con numero step\n",
    "    for i in results_data.index:\n",
    "        step_annotation = plt.annotate(\n",
    "            i+1,\n",
    "            (x_data[i], y_data[i]),\n",
    "            #horizontalalignment=\"center\",\n",
    "            xytext=(5, 4),\n",
    "            textcoords=\"offset points\"\n",
    "        )\n",
    "        texts.append(step_annotation)\n",
    "\n",
    "    adjust_text(texts, x=list(x_data), y=list(y_data))\n",
    "    \n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea 'Cl/K vs Age'\n",
    "\n",
    "def plot_cl_k_age():\n",
    "    \n",
    "    # sceglie su quale steps voui zoomare (inizia da 0), DA MODIFICARE MANUALMENTE DALL'UTENTE\n",
    "    \n",
    "    point_plot(results_data['Cl/K'], results_data['Age'], zoom_to_steps_cl_k_age, color='green')\n",
    "\n",
    "    plt.ylabel('Apparent age [Ma]')\n",
    "    plt.xlabel('Cl/K')\n",
    "\n",
    "plot_cl_k_age()\n",
    "\n",
    "# salva in formato SVG\n",
    "    # SVG è un format di immagine vettoriale, puoi usarlo direttamente in Word come un'altra immagine\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_cl_k_age\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_cl_k_age\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea 'Ca/K vs Age'\n",
    "\n",
    "def plot_ca_k_age():\n",
    "    \n",
    "    # sceglie su quale steps voui zoomare (inizia da 0), DA MODIFICARE MANUALMENTE DALL'UTENTE\n",
    "\n",
    "    point_plot(results_data['Ca/K'], results_data['Age'], zoom_to_steps_ca_k_age, color='yellow')\n",
    "\n",
    "    #plt.title('Ca/K vs Age')\n",
    "    plt.xlabel('Ca/K')\n",
    "    plt.ylabel('Apparent age [Ma]')\n",
    "\n",
    "plot_ca_k_age()\n",
    "\n",
    "# salva in formato SVG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_ca_k_age\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_ca_k_age\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea 'Ca/K vs Cl/K'\n",
    "\n",
    "def plot_ca_k_cl_k():\n",
    "    \n",
    "    # sceglie su quale steps voui zoomare (inizia da 0), DA MODIFICARE MANUALMENTE DALL'UTENTE\n",
    "    point_plot(results_data['Ca/K'], results_data['Cl/K'], zoom_to_steps_ca_k_cl_k, color='cyan')\n",
    "\n",
    "    #plt.title('Ca/K vs Cl/K')\n",
    "    plt.xlabel('Ca/K')\n",
    "    plt.ylabel('Cl/K')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plot_ca_k_cl_k()\n",
    "\n",
    "# salva in formato SVG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_ca_k_cl_k\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_ca_k_cl_k\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea Isocrona '36Ar/39Ar vs 39Ar/40Ar'\n",
    "x = results_data['39/40'].dropna()\n",
    "y = results_data['36/40'].dropna()\n",
    "\n",
    "plt.plot(x, y, 'o', color='black'),\n",
    "\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "plt.plot(x, m*x + b, color='black')\n",
    "plt.title('36Ar/39Ar vs 39Ar/40Ar')\n",
    "plt.xlabel('39Ar/40Ar')\n",
    "plt.ylabel('36Ar/39Ar')\n",
    "plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# salva in formato SVG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_isochron\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_isochron\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea Spectrum Age plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea la cumulata dei valori nella colonna '% 39Ar' del dataframe results data\n",
    "cumulative = results_data['% 39Ar'].cumsum()\n",
    "cumulative_df = pd.DataFrame(cumulative)\n",
    "\n",
    "# Crea dataframe Age+2error\n",
    "age_più_2error_df = pd.DataFrame(results_data['Age+2error'])\n",
    "\n",
    "# Crea dataframe Age-2error\n",
    "age_meno_2error_df = pd.DataFrame(results_data['Age-2error'])\n",
    "\n",
    "# Duplica i valori della cumulata\n",
    "double_cumulative_df = pd.DataFrame(np.repeat(cumulative_df.values,2,axis=0))\n",
    "double_cumulative_df.columns = cumulative_df.columns\n",
    "\n",
    "# Rinomina il database double_cumulative (Cum%39)\n",
    "double_cumulative_df = double_cumulative_df.rename(columns={\"% 39Ar\": \"Cum%39\"})\n",
    "\n",
    "# Cancella l'ultima riga di (Cum%39)\n",
    "#print(double_cumulative_df.index[-1])\n",
    "double_cumulative_df = pd.DataFrame(double_cumulative_df.drop(index=double_cumulative_df.index[-1]))\n",
    "\n",
    "# Aggiungi \"O\" alla prima riga di (Cum%39)\n",
    "double_cumulative_df.loc[-1] = [0]  # adding a row\n",
    "double_cumulative_df.index = double_cumulative_df.index + 1  # shifting index\n",
    "double_cumulative_df = double_cumulative_df.sort_index()  # sorting by index\n",
    "\n",
    "# Duplica i valori di (Age+2error)\n",
    "double_age_più_2error_df = pd.DataFrame(np.repeat(age_più_2error_df.values,2,axis=0))\n",
    "double_age_più_2error_df.columns = age_più_2error_df.columns\n",
    "\n",
    "# Duplica i valori di (Age+2error)\n",
    "double_age_meno_2error_df = pd.DataFrame(np.repeat(age_meno_2error_df.values,2,axis=0))\n",
    "double_age_meno_2error_df.columns = age_meno_2error_df.columns\n",
    "\n",
    "# Unione dei dataframe\n",
    "double_cumulative_df['Age+2error'] = double_age_più_2error_df['Age+2error']\n",
    "double_cumulative_df['Age-2error'] = double_age_meno_2error_df['Age-2error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrum Age\n",
    "def plot_spectrum_age():\n",
    "    plt.plot(double_cumulative_df['Cum%39'], double_cumulative_df['Age+2error'], label='Age+2error', color='blue')\n",
    "    plt.plot(double_cumulative_df['Cum%39'], double_cumulative_df['Age-2error'], label='Age−2error', color='orange')\n",
    "    #plt.title('Age Spectrum')\n",
    "    plt.xlabel('Cumulative %Ar39 released')\n",
    "    plt.ylabel('Apparent age [Ma]')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    ymin = results_data['Age-2error'][zoom_to_steps_spectrum].min()\n",
    "    ymax = results_data['Age+2error'][zoom_to_steps_spectrum].max()\n",
    "    \n",
    "    if ((ymin-(ymax-ymin)/4) < 0):\n",
    "        plt.ylim(( 0, ymax+(ymax-ymin)/8 ))\n",
    "    else:\n",
    "        plt.ylim(( ymin-(ymax-ymin)/4, ymax+(ymax-ymin)/8 ))\n",
    "    plt.xlim(0,100)\n",
    "\n",
    "    #etichette sul grafico\n",
    "    for i in results_data.index:\n",
    "        if i not in show_labels_for_steps:\n",
    "            continue\n",
    "\n",
    "        xpos = (double_cumulative_df['Cum%39'][i*2] + double_cumulative_df['Cum%39'][i*2+1]) / 2\n",
    "\n",
    "        # etichetta con età\n",
    "        plt.annotate(\n",
    "            '%.1f' % results_data['Age'][i],\n",
    "            (xpos, results_data['Age-2error'][i]),\n",
    "            rotation=-90,\n",
    "            horizontalalignment=\"center\",\n",
    "            va=\"top\",\n",
    "            xytext=(-1, -4),\n",
    "            textcoords=\"offset points\"\n",
    "        )\n",
    "\n",
    "        # etichetta con numero step\n",
    "        plt.annotate(\n",
    "            i+1,\n",
    "            (xpos, results_data['Age+2error'][i]),\n",
    "            horizontalalignment=\"center\",\n",
    "            xytext=(0, 4),\n",
    "            textcoords=\"offset points\"\n",
    "        )\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "plot_spectrum_age()\n",
    "\n",
    "# salva in formato SVG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_spectrum\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_spectrum\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLLO SUL GUADAGNO\n",
    "# Crea 'F/IC0_39Ar vs Cum%39'\n",
    "\n",
    "def plot_gain_39():\n",
    "    \n",
    "    plt.scatter(cumulative_df,df_data['F/IC0_39Ar'],marker= 'o', color = 'black' )\n",
    "    #plt.title('F/IC0_39Ar vs Cum%39')\n",
    "    plt.xlabel('Cum%39')\n",
    "    plt.ylabel('F/IC0 39Ar')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "    #print(df_data.loc[:,'F/IC0_39Ar'])\n",
    "    #print(cumulative_df)\n",
    "\n",
    "#plot_gain_39()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLOT 'gainF/IC0 vs 40Ar F' and 'gainIC0/IC1 vs gainF/IC0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea 'gainF/IC0 vs 40Ar F'\n",
    "\n",
    "def plot_gain_40():\n",
    "    plt.scatter(df_data['40Ar F'], df_data['gainF/IC0'], marker='o', color='black')\n",
    "    #plt.title('gainF/IC0 vs 40Ar F')\n",
    "    plt.xlabel('40Ar F')\n",
    "    plt.ylabel('gainF/IC0')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "#plot_gain_40()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea la variabile 'gainIC1/IC0' da 'gainIC0/IC1\n",
    "\n",
    "df_data.loc[:,'gainIC1/IC0'] = pow(df_data['gainIC0/IC1'].values, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crea 'gainIC1/IC0 vs gainF/IC0'\n",
    "\n",
    "def plot_gain_gain_1():\n",
    "    plt.scatter(df_data['gainF/IC0'], df_data['gainIC1/IC0'], marker='o', color='black')\n",
    "    #plt.title('gainIC1/IC0 vs gainF/IC0')\n",
    "    plt.xlabel('gainF/IC0')\n",
    "    plt.ylabel('gainIC1/IC0')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "#plot_gain_gain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea 'gainIC0/IC1 vs gainF/IC0'\n",
    "\n",
    "def plot_gain_gain_2():\n",
    "    plt.scatter(df_data['gainF/IC0'], df_data['gainIC0/IC1'], marker='o', color='black')\n",
    "    #plt.title('gainIC1/IC0 vs gainF/IC0')\n",
    "    plt.xlabel('gainF/IC0')\n",
    "    plt.ylabel('gainIC0/IC1')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "#plot_gain_gain_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea figura composta dati campioni (2x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_scale = 0.75\n",
    "\n",
    "cm = 1/2.54\n",
    "plt.subplots(figsize=(25*cm/text_scale, 15*cm/text_scale))\n",
    "\n",
    "grid_col = 2\n",
    "grid_row = 2\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 1)\n",
    "plot_ca_k_age()\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 2)\n",
    "plot_cl_k_age()\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 3)\n",
    "plot_ca_k_cl_k()\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 4)\n",
    "plot_spectrum_age()\n",
    "\n",
    "# salva in formato SVG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_all\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_all\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea figura composta dati strumento (2x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_scale = 0.6\n",
    "\n",
    "cm = 1/2.54\n",
    "plt.subplots(figsize=(25*cm/text_scale, 15*cm/text_scale))\n",
    "\n",
    "grid_col = 2\n",
    "grid_row = 2\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 1)\n",
    "plot_gain_39()\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 2)\n",
    "plot_gain_40()\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 3)\n",
    "plot_gain_gain_1()\n",
    "\n",
    "plt.subplot(grid_col, grid_row, 4)\n",
    "plot_gain_gain_2()\n",
    "\n",
    "filter_data_min = df_data.iat[0, 0]\n",
    "\n",
    "plt.suptitle(sample_name + ', ' + date_analysis.strftime('%d %b %Y'), fontsize=18)\n",
    "\n",
    "# salva in formato SVG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_instrument\" + \".svg\",\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0\n",
    ")\n",
    "\n",
    "# salva in formato PNG\n",
    "    \n",
    "plt.savefig(\n",
    "directory_sample_plot + \"/\" + sample_name + \"_instrument\" + \".png\",\n",
    "dpi=300,\n",
    "bbox_inches=\"tight\",\n",
    "pad_inches=0.1\n",
    ")\n",
    "\n",
    "# salva in formato PNG nella cartella \"plots_instruments\" dove sono raccolti insieme tutti i dati dello strumento\n",
    "\n",
    "directory = \"Instrument_plots\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "plt.savefig(\n",
    "    os.path.join(directory, date_analysis.strftime('%Y-%m-%d') + \" \" + sample_name + \".png\"),\n",
    "\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0.1\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
